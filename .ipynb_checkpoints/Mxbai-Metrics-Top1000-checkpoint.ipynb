{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f221da-1681-4728-9bbd-e76c92c150a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install sentence_transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4201c61d-4266-4808-9bbb-355428774d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import ndcg_score\n",
    "import torch\n",
    "import os\n",
    "import tqdm\n",
    "import time\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import multiprocessing as mp\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95716164-6f11-48c1-9f8a-10051c6582e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_collection = pd.read_csv(\"Data/collection.tsv\", sep=\"\\t\", names=[\"doc_id\", \"passage\"], on_bad_lines=\"skip\")\n",
    "df_queries = pd.read_csv(\"Data/queries.test.tsv\", sep=\"\\t\", names=[\"query_id\", \"query\"], on_bad_lines=\"skip\")\n",
    "df_qrels = pd.read_csv(\"Data/qrels.test.tsv\", sep=\"\\t\", names=[\"query_id\", \"doc_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b905b045-241a-4f3d-a1e0-2185b81fad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load passage embeddings from pickle\n",
    "Basemodel: embedding_passages\n",
    "\"\"\"\n",
    "embedding_path = \"Data/embeddings\"\n",
    "start = time.time()\n",
    "with open(f'{embedding_path}/embedding_passages_only_test_v0.pkl', 'rb') as file:\n",
    "    embedding_data = pickle.load(file)\n",
    "print(f\"Duration: {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e167b4-eeb9-4f68-9869-fea49113240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load query embeddings from pickle\n",
    "Basemodel: query_embeddings\n",
    "\"\"\"\n",
    "embedding_path = \"Data/embeddings\"\n",
    "start = time.time()\n",
    "with open(f'{embedding_path}/query_embeddings_test_v0.pkl', 'rb') as file:\n",
    "    query_data = pickle.load(file)\n",
    "print(f\"Duration: {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d68c281-3c1f-47a9-9122-426859a877b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(embedding_data[\"embeddings\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0063fcd4-de58-4906-897c-836d1a251e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(query_data[\"embeddings\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ecba4-c613-4127-8e91-29a18f85aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_doc_ids = set(df_qrels['doc_id'].unique())\n",
    "\n",
    "print(len(relevant_doc_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9ebffd-b16a-4098-8c8a-4db585232cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load BM25 Results\n",
    "\"\"\"\n",
    "#with open('Data/models/bm25_passages.pkl', 'rb') as f:\n",
    "#    bm25_results = pickle.load(f)\n",
    "\n",
    "\"\"\"\n",
    "Load Top 1000 Docs for each test query\n",
    "\"\"\"\n",
    "#with open('Data/models/queries_test_1000_passages.pkl', 'rb') as f:\n",
    "#    top_1000_docs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dc1479-4534-44d1-b2ed-aa40fd1b5541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mrr(ranked_doc_ids, relevant_doc_ids, k=10):\n",
    "    for rank, doc_id in enumerate(ranked_doc_ids[:k], start=1):\n",
    "        if doc_id in relevant_doc_ids:\n",
    "            return 1.0 / rank\n",
    "    return 0.0\n",
    "\n",
    "def calculate_ndcg(ranked_doc_ids, relevant_doc_ids, k=20):\n",
    "    relevance = np.zeros(k)\n",
    "    for i, doc_id in enumerate(ranked_doc_ids[:k]):\n",
    "        if doc_id in relevant_doc_ids:\n",
    "            relevance[i] = 1\n",
    "    return ndcg_score([relevance], [np.ones_like(relevance)], k=k)\n",
    "\n",
    "def get_top_k_embeddings(top_k_indices, embedding_data):\n",
    "    #top_k_indices = top_k_indices.flatten()\n",
    "    #print(top_k_indices)\n",
    "    \n",
    "    # Extract Embeddings for top1000 Embeddings\n",
    "    top_k_embeddings = embedding_data[\"embeddings\"][top_k_indices]\n",
    "    \n",
    "    top_k_doc_ids = [embedding_data[\"doc_ids\"][idx] for idx in top_k_indices]\n",
    "    \n",
    "    return top_k_embeddings, top_k_doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe3085-b93f-4abd-8118-b7247f303879",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate Metrics with the top1000 BM25 passages.\n",
    "\"\"\"\n",
    "\n",
    "# Limit Queries\n",
    "M = len(query_data['query_ids'])\n",
    "passage_mrr_scores = []\n",
    "document_mrr_scores = []\n",
    "ndcg_scores = []\n",
    "index_to_query_id = query_data['query_ids']\n",
    "\n",
    "print(\"Start Similarity Calculation\")\n",
    "start = time.time()\n",
    "\n",
    "for i, (query_id, query_embedding) in enumerate(zip(query_data['query_ids'], query_data['embeddings'])):\n",
    "    if i >= M:\n",
    "        break\n",
    "\n",
    "    actual_query_id = index_to_query_id[i]\n",
    "\n",
    "    top_k_passages = top_1000_docs[i]\n",
    "\n",
    "    # Extract top k Embeddings\n",
    "    top_k_embeddings, top_k_doc_ids = get_top_k_embeddings(top_k_passages, embedding_data)\n",
    "    \n",
    "    similarities = np.dot(query_embedding.reshape(1, -1), top_k_embeddings.T)[0]\n",
    "    ranked_indices = np.argsort(similarities)[::-1][:20]  # Top 20 f√ºr NDCG@20\n",
    "    \n",
    "    ranked_passage_ids = [top_k_doc_ids[idx] for idx in ranked_indices]\n",
    "    relevant_doc_ids = set(df_qrels[df_qrels['query_id'] == actual_query_id]['doc_id'])\n",
    "    \n",
    "    passage_mrr = calculate_mrr(ranked_passage_ids, relevant_doc_ids)\n",
    "    passage_mrr_scores.append(passage_mrr)\n",
    "    \n",
    "    ndcg = calculate_ndcg(ranked_passage_ids, relevant_doc_ids)\n",
    "    ndcg_scores.append(ndcg)\n",
    "    \n",
    "    doc_scores = {}\n",
    "    for idx in ranked_indices:\n",
    "        doc_id = top_k_doc_ids[idx]\n",
    "        doc_scores[doc_id] = max(doc_scores.get(doc_id, 0), similarities[idx])\n",
    "    \n",
    "    ranked_doc_ids = sorted(doc_scores, key=doc_scores.get, reverse=True)\n",
    "    document_mrr = calculate_mrr(ranked_doc_ids, relevant_doc_ids)\n",
    "    document_mrr_scores.append(document_mrr)\n",
    "    document_ndcg = calculate_ndcg(ranked_doc_ids, relevant_doc_ids)\n",
    "    document_ndcg_scores.append(document_ndcg)\n",
    "\n",
    "print(f\"Duration for all Queries: {time.time() - start} seconds\")\n",
    "mean_passage_mrr = np.mean(passage_mrr_scores)\n",
    "mean_document_mrr = np.mean(document_mrr_scores)\n",
    "mean_ndcg = np.mean(ndcg_scores)\n",
    "mean_document_ndcg = np.mean(document_ndcg_scores)\n",
    "\n",
    "print(f\"Passage MRR@10: {mean_passage_mrr:.4f}\")\n",
    "print(f\"Document MRR@10: {mean_document_mrr:.4f}\")\n",
    "print(f\"Passage NDCG@20: {mean_ndcg:.4f}\")\n",
    "print(f\"Document NDCG@20: {mean_document_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41976976-e6a9-48ea-a7b0-7114e175974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ergebnisse\n",
    "\n",
    "Baseline\n",
    "Mean Passage MRR@10: 0.1901\n",
    "Mean Document MRR@10: 0.1939\n",
    "Mean NDCG@20: 0.1629\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
