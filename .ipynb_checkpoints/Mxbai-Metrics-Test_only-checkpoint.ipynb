{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f221da-1681-4728-9bbd-e76c92c150a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install sentence_transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4201c61d-4266-4808-9bbb-355428774d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import ndcg_score\n",
    "import torch\n",
    "import os\n",
    "import tqdm\n",
    "import time\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import multiprocessing as mp\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95716164-6f11-48c1-9f8a-10051c6582e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_queries = pd.read_csv(\"Data/queries.test.tsv\", sep=\"\\t\", names=[\"query_id\", \"query\"], on_bad_lines=\"skip\")\n",
    "df_qrels = pd.read_csv(\"Data/qrels.test.tsv\", sep=\"\\t\", names=[\"query_id\", \"doc_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b905b045-241a-4f3d-a1e0-2185b81fad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load passage embeddings from pickle\n",
    "Basemodel: embedding_passages_only_test_v0\n",
    "\"\"\"\n",
    "embedding_path = \"Data/embeddings\"\n",
    "start = time.time()\n",
    "with open(f'{embedding_path}/embedding_passages_only_test_v0.pkl', 'rb') as file:\n",
    "    embedding_data = pickle.load(file)\n",
    "print(f\"Duration: {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e167b4-eeb9-4f68-9869-fea49113240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load query embeddings from pickle\n",
    "Basemodel: query_embeddings_test_v0.pkl\n",
    "\"\"\"\n",
    "embedding_path = \"Data/embeddings\"\n",
    "start = time.time()\n",
    "with open(f'{embedding_path}/query_embeddings_test_v0.pkl', 'rb') as file:\n",
    "    query_data = pickle.load(file)\n",
    "print(f\"Duration: {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d68c281-3c1f-47a9-9122-426859a877b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(embedding_data[\"embeddings\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0063fcd4-de58-4906-897c-836d1a251e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(query_data[\"embeddings\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ecba4-c613-4127-8e91-29a18f85aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_doc_ids = set(df_qrels['doc_id'].unique())\n",
    "\n",
    "print(len(relevant_doc_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dc1479-4534-44d1-b2ed-aa40fd1b5541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mrr(ranked_doc_ids, relevant_doc_ids, k=10):\n",
    "    for rank, doc_id in enumerate(ranked_doc_ids[:k], start=1):\n",
    "        if doc_id in relevant_doc_ids:\n",
    "            return 1.0 / rank\n",
    "    return 0.0\n",
    "\n",
    "def calculate_ndcg(ranked_doc_ids, relevant_doc_ids, k=20):\n",
    "    relevance = np.zeros(k)\n",
    "    for i, doc_id in enumerate(ranked_doc_ids[:k]):\n",
    "        if doc_id in relevant_doc_ids:\n",
    "            relevance[i] = 1\n",
    "    return ndcg_score([relevance], [np.ones_like(relevance)], k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac60597-7bb2-4c5c-8c6a-1e18c210a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculating similarity with already computed query embeddings\n",
    "\"\"\"\n",
    "# Limit Queries\n",
    "M = len(query_data['query_ids'])\n",
    "#M = 100\n",
    "# Retrieval und MRR-Berechnung\n",
    "passage_mrr_scores = []\n",
    "document_mrr_scores = []\n",
    "ndcg_scores = []\n",
    "document_ndcg_scores = []\n",
    "query_similarities = {}\n",
    "index_to_query_id = query_data['query_ids']\n",
    "\n",
    "print(\"Start Similarity Calculation\")\n",
    "start = time.time()\n",
    "\n",
    "for i, (query_id, query_embedding) in enumerate(zip(query_data['query_ids'], query_data['embeddings'])):\n",
    "    if i >= M:\n",
    "        break\n",
    "    if(i % 1000 == 0):\n",
    "        print(f\"Query: {i} Duration: {time.time() - start} seconds\")\n",
    "\n",
    "    actual_query_id = index_to_query_id[i]\n",
    "    \n",
    "    # Cosine Similarity (jetzt eigentlich Skalarprodukt)\n",
    "    similarities = np.dot(query_embedding.reshape(1, -1), embedding_data[\"embeddings\"].T)[0]\n",
    "    ranked_indices = np.argsort(similarities)[::-1][:20]  # Erhöht auf 20 für NDCG@20\n",
    "    \n",
    "    ranked_passage_ids = [embedding_data[\"doc_ids\"][idx] for idx in ranked_indices]\n",
    "    relevant_doc_ids = set(df_qrels[df_qrels['query_id'] == actual_query_id]['doc_id'])\n",
    "    \n",
    "    passage_mrr = calculate_mrr(ranked_passage_ids, relevant_doc_ids)\n",
    "    passage_mrr_scores.append(passage_mrr)\n",
    "    \n",
    "    # NDCG@20\n",
    "    ndcg = calculate_ndcg(ranked_passage_ids, relevant_doc_ids)\n",
    "    ndcg_scores.append(ndcg)\n",
    "    \n",
    "    # Document-wise Ranking\n",
    "    doc_scores = {}\n",
    "    for idx in ranked_indices:\n",
    "        doc_id = embedding_data[\"doc_ids\"][idx]\n",
    "        doc_scores[doc_id] = max(doc_scores.get(doc_id, 0), similarities[idx])\n",
    "    \n",
    "    ranked_doc_ids = sorted(doc_scores, key=doc_scores.get, reverse=True)\n",
    "    document_mrr = calculate_mrr(ranked_doc_ids, relevant_doc_ids)\n",
    "    document_mrr_scores.append(document_mrr)\n",
    "    document_ndcg = calculate_ndcg(ranked_doc_ids, relevant_doc_ids)\n",
    "    document_ndcg_scores.append(document_ndcg)\n",
    "\n",
    "print(f\"Duration for all Queries: {time.time() - start} seconds\")\n",
    "mean_passage_mrr = np.mean(passage_mrr_scores)\n",
    "mean_document_mrr = np.mean(document_mrr_scores)\n",
    "mean_ndcg = np.mean(ndcg_scores)\n",
    "mean_document_ndcg = np.mean(document_ndcg_scores)\n",
    "\n",
    "print(f\"Passage MRR@10: {mean_passage_mrr:.4f}\")\n",
    "print(f\"Document MRR@10: {mean_document_mrr:.4f}\")\n",
    "print(f\"Passage NDCG@20: {mean_ndcg:.4f}\")\n",
    "print(f\"Document NDCG@20: {mean_document_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f24cf76-2d1d-4ec3-b131-c57bd60f16a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ergebnisse\n",
    "\n",
    "# Baseline\n",
    "Passage MRR@10: 0.4701\n",
    "Document MRR@10: 0.4802\n",
    "Passage NDCG@20: 0.3476\n",
    "\n",
    "# Finetuned Model\n",
    "Mean Passage MRR@10: 0.3658\n",
    "Mean Document MRR@10: 0.3792\n",
    "Mean NDCG@20: 0.3091\n",
    "\n",
    "# Finetuned v3\n",
    "Passage MRR@10: 0.4114\n",
    "Document MRR@10: 0.4189\n",
    "Passage NDCG@20: 0.3016\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
